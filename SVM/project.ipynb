{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E0KdSyBYY1wK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# constructor for decision tree node\n",
        "class DecisionTreeNode:\n",
        "    def __init__(self, data, labels, nmin):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.nmin = nmin\n",
        "        self.split_feature = None\n",
        "        self.split_value = None\n",
        "        self.left_child = None\n",
        "        self.right_child = None\n",
        "        self.label = self.find_dominant_label(labels)\n",
        "\n",
        "    # get the dominant label for the current node\n",
        "    def find_dominant_label(self, labels):\n",
        "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "        dominant_label = unique_labels[np.argmax(counts)]\n",
        "        return dominant_label\n",
        "\n",
        "    # split the node based on the best gain\n",
        "    def split(self):\n",
        "        num_features = self.data.shape[1]\n",
        "        best_gain = 0\n",
        "\n",
        "        for feature in range(num_features):\n",
        "            # evaluates the Information Gain for each unique number\n",
        "            # the one that results in the highest gain is selected\n",
        "            # as the splitting threshold for that particular feature\n",
        "            unique_values = np.unique(self.data[:, feature])\n",
        "            for value in unique_values:\n",
        "                left_indices = self.data[:, feature] <= value\n",
        "                right_indices = ~left_indices\n",
        "\n",
        "                # skip if the split does not meet the minimum size requirement\n",
        "                if np.sum(left_indices) < self.nmin or np.sum(right_indices) < self.nmin:\n",
        "                    continue\n",
        "\n",
        "                gain = self.calculate_information_gain(left_indices, right_indices)\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    self.split_feature = feature\n",
        "                    self.split_value = value\n",
        "\n",
        "        # leaf node check\n",
        "        if best_gain == 0:\n",
        "            return False\n",
        "\n",
        "        # perform the split\n",
        "        left_indices = self.data[:, self.split_feature] <= self.split_value\n",
        "        right_indices = ~left_indices\n",
        "\n",
        "        left_data, left_labels = self.data[left_indices], self.labels[left_indices]\n",
        "        right_data, right_labels = self.data[right_indices], self.labels[right_indices]\n",
        "\n",
        "        self.left_child = DecisionTreeNode(left_data, left_labels, self.nmin)\n",
        "        self.right_child = DecisionTreeNode(right_data, right_labels, self.nmin)\n",
        "\n",
        "        # node split\n",
        "        return True\n",
        "\n",
        "    # IG = E(parent) - [weighted average] \\cdot E(children)\n",
        "    def calculate_information_gain(self, left_indices, right_indices):\n",
        "\n",
        "        left_entropy = self.calculate_entropy(self.labels[left_indices])\n",
        "        right_entropy = self.calculate_entropy(self.labels[right_indices])\n",
        "        parent_entropy = self.calculate_entropy(self.labels)\n",
        "\n",
        "        left_weight = np.sum(left_indices) / len(self.labels)\n",
        "        right_weight = np.sum(right_indices) / len(self.labels)\n",
        "\n",
        "        information_gain = parent_entropy - (left_weight * left_entropy + right_weight * right_entropy)\n",
        "        return information_gain\n",
        "\n",
        "    # E = - \\sum p(X) \\cdot log_{2}(p(X))\n",
        "    # where p(X) = \\frac{#x}{n}\n",
        "    def calculate_entropy(self, labels):\n",
        "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "        probabilities = counts / len(labels)\n",
        "        entropy = -np.sum(probabilities * np.log2(probabilities + 1e-10))  # add a small constant to avoid log(0)\n",
        "        return entropy\n",
        "\n",
        "def create_decision_tree(data, labels, nmin):\n",
        "    # initialize a decision tree\n",
        "    # w/ features, targets, nmin\n",
        "    root = DecisionTreeNode(data, labels, nmin)\n",
        "    stack = [root]\n",
        "\n",
        "    while stack:\n",
        "        current_node = stack.pop()\n",
        "        # if the conditions for splitting are met,\n",
        "        # append the left and right child nodes to the stack\n",
        "        if current_node.split() and len(current_node.labels) >= 2 * nmin:\n",
        "            stack.append(current_node.right_child)\n",
        "            stack.append(current_node.left_child)\n",
        "\n",
        "    return root\n",
        "\n",
        "def predict(tree, sample):\n",
        "    # check if leaf node\n",
        "    if tree.split_feature is None:\n",
        "        return tree.label\n",
        "\n",
        "    # check if the feature value of the sample corresponding\n",
        "    # to the feature used for the split in the current node\n",
        "    # is less than or equal to the split value\n",
        "    if sample[tree.split_feature] <= tree.split_value:\n",
        "        return predict(tree.left_child, sample)\n",
        "    else:\n",
        "        return predict(tree.right_child, sample)\n",
        "\n",
        "def make_predictions(tree, data):\n",
        "    predictions = [predict(tree, sample) for sample in data]\n",
        "    return np.array(predictions)\n",
        "\n",
        "def calculate_accuracy(predictions, true_labels):\n",
        "    correct_predictions = np.sum(predictions == true_labels)\n",
        "    accuracy = correct_predictions / len(true_labels)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgWvacex2Yjj"
      },
      "source": [
        "## Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8CXOz-1ZqxH"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# load dataset\n",
        "# code from extras doc\n",
        "iris_df = pd.read_csv(\"iris.csv\", names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"])\n",
        "iris_df = iris_df.replace({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n",
        "\n",
        "# extract features (all columns except last)\n",
        "data = iris_df.iloc[:, :-1].values\n",
        "# extract target labels (last column)\n",
        "labels = iris_df.iloc[:, -1].values\n",
        "\n",
        "# define values of nmin\n",
        "nmin_values = [5, 10, 15, 20]\n",
        "\n",
        "# perform 10-fold cross-validation for each value of nmin\n",
        "for nmin in nmin_values:\n",
        "\n",
        "    print(f\"\\nResults for nmin={nmin}\\n\")\n",
        "    print(f\"{'Fold':<5}{'Accuracy':<15}\")\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    # initialize KFold with 10 folds\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(data), start=1):\n",
        "        X_train, X_test = data[train_index], data[test_index]\n",
        "        y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "        # train decision tree on the training set\n",
        "        decision_tree = create_decision_tree(X_train, y_train, nmin)\n",
        "\n",
        "        # make predictions on the testing set\n",
        "        predicted_labels = make_predictions(decision_tree, X_test)\n",
        "\n",
        "        # calculate accuracy on the testing set\n",
        "        accuracy = calculate_accuracy(predicted_labels, y_test)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "        print(f\"{i:<5}{accuracy*100:.2f}%\")\n",
        "\n",
        "    # calculate and print the average accuracy and std dev\n",
        "    print(\"-\" * 20)\n",
        "    # Calculate average accuracy and standard deviation\n",
        "    average_accuracy = np.mean(accuracies)\n",
        "    std_dev_accuracy = np.std(accuracies)\n",
        "\n",
        "    # Print average accuracy and standard deviation\n",
        "    print(f\"Average accuracy: {average_accuracy*100:.2f}%\")\n",
        "    print(f\"Standard deviation: {std_dev_accuracy*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlM9Ycvn2lzg"
      },
      "source": [
        "## Spambase dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "073Ny-5K2orJ",
        "outputId": "dc1939af-756f-4d1f-f9d6-7af10e87276c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Results for nmin=5\n",
            "\n",
            "Fold Accuracy       \n",
            "--------------------\n",
            "1    91.96%\n",
            "2    91.74%\n",
            "3    91.52%\n",
            "4    94.13%\n",
            "5    91.96%\n",
            "6    90.65%\n",
            "7    91.52%\n",
            "8    91.74%\n",
            "9    93.48%\n",
            "10   93.70%\n",
            "--------------------\n",
            "Average accuracy: 92.24%\n",
            "Standard deviation: 1.07%\n",
            "\n",
            "Results for nmin=10\n",
            "\n",
            "Fold Accuracy       \n",
            "--------------------\n",
            "1    92.39%\n",
            "2    91.30%\n",
            "3    92.61%\n",
            "4    93.91%\n",
            "5    91.52%\n",
            "6    90.00%\n",
            "7    91.74%\n",
            "8    92.17%\n",
            "9    91.74%\n",
            "10   93.91%\n",
            "--------------------\n",
            "Average accuracy: 92.13%\n",
            "Standard deviation: 1.12%\n",
            "\n",
            "Results for nmin=15\n",
            "\n",
            "Fold Accuracy       \n",
            "--------------------\n",
            "1    91.74%\n",
            "2    89.78%\n",
            "3    90.22%\n",
            "4    93.91%\n",
            "5    91.09%\n",
            "6    90.22%\n",
            "7    90.43%\n",
            "8    91.74%\n",
            "9    91.52%\n",
            "10   92.39%\n",
            "--------------------\n",
            "Average accuracy: 91.30%\n",
            "Standard deviation: 1.18%\n",
            "\n",
            "Results for nmin=20\n",
            "\n",
            "Fold Accuracy       \n",
            "--------------------\n",
            "1    89.78%\n",
            "2    89.57%\n",
            "3    89.57%\n",
            "4    93.70%\n",
            "5    91.30%\n",
            "6    90.87%\n",
            "7    91.74%\n",
            "8    92.39%\n",
            "9    91.96%\n",
            "10   92.83%\n",
            "--------------------\n",
            "Average accuracy: 91.37%\n",
            "Standard deviation: 1.35%\n",
            "\n",
            "Results for nmin=25\n",
            "\n",
            "Fold Accuracy       \n",
            "--------------------\n",
            "1    91.09%\n",
            "2    87.83%\n",
            "3    90.00%\n",
            "4    93.26%\n",
            "5    88.91%\n",
            "6    91.09%\n",
            "7    89.78%\n",
            "8    91.74%\n",
            "9    91.96%\n",
            "10   91.96%\n",
            "--------------------\n",
            "Average accuracy: 90.76%\n",
            "Standard deviation: 1.54%\n"
          ]
        }
      ],
      "source": [
        "# load dataset\n",
        "# code from extras doc\n",
        "spambase_df = pd.read_csv(\"spambase.csv\")\n",
        "\n",
        "# extract features (all columns except last)\n",
        "data = spambase_df.iloc[:, :-1].values\n",
        "# extract target labels (last column)\n",
        "labels = spambase_df.iloc[:, -1].values\n",
        "\n",
        "# define values of nmin\n",
        "nmin_values = [5, 10, 15, 20, 25]\n",
        "\n",
        "# perform 10-fold cross-validation for each value of nmin\n",
        "for nmin in nmin_values:\n",
        "\n",
        "    print(f\"\\nResults for nmin={nmin}\\n\")\n",
        "    print(f\"{'Fold':<5}{'Accuracy':<15}\")\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    # initialize KFold with 10 folds\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(data), start=1):\n",
        "        X_train, X_test = data[train_index], data[test_index]\n",
        "        y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "        # train decision tree on the training set\n",
        "        decision_tree = create_decision_tree(X_train, y_train, nmin)\n",
        "\n",
        "        # make predictions on the testing set\n",
        "        predicted_labels = make_predictions(decision_tree, X_test)\n",
        "\n",
        "        # calculate accuracy on the testing set\n",
        "        accuracy = calculate_accuracy(predicted_labels, y_test)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "        print(f\"{i:<5}{accuracy*100:.2f}%\")\n",
        "\n",
        "    # calculate and print the average accuracy and std dev\n",
        "    print(\"-\" * 20)\n",
        "    # Calculate average accuracy and standard deviation\n",
        "    average_accuracy = np.mean(accuracies)\n",
        "    std_dev_accuracy = np.std(accuracies)\n",
        "\n",
        "    # Print average accuracy and standard deviation\n",
        "    print(f\"Average accuracy: {average_accuracy*100:.2f}%\")\n",
        "    print(f\"Standard deviation: {std_dev_accuracy*100:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
